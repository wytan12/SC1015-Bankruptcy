{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63f58e0",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "\n",
    "#### What is XGBoost?\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is a popular gradient boosting framework that is designed to optimize performance and speed in tree ensemble learning algorithms. It uses a combination of gradient boosting and regularization techniques to prevent overfitting and improve model accuracy. XGBoost has become a popular choice for machine learning competitions and is widely used in industry for its performance and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b9eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b2daf",
   "metadata": {},
   "source": [
    "## Functions to calculate TPR and FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76172d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TPR(actual, prediction):\n",
    "    TP = confusion_matrix(actual, prediction)[1][1]\n",
    "    FN = confusion_matrix(actual, prediction)[1][0]\n",
    "    TPR = (TP/(TP+FN))\n",
    "    \n",
    "    return TPR\n",
    "    \n",
    "def get_FPR(actual, prediction):\n",
    "    FP = confusion_matrix(actual, prediction)[0][1]\n",
    "    TN = confusion_matrix(actual, prediction)[0][0]\n",
    "    FPR = (FP/(FP+TN))\n",
    "    \n",
    "    return FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e180efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', ' Debt ratio %', ' Borrowing dependency',\n",
       "       ' Liability to Equity', ' Net Income to Stockholder's Equity',\n",
       "       ' Persistent EPS in the Last Four Seasons',\n",
       "       ' ROA(C) before interest and depreciation before interest',\n",
       "       ' Net worth/Assets',\n",
       "       ' ROA(B) before interest and depreciation after tax',\n",
       "       ' ROA(A) before interest and % after tax',\n",
       "       ' Net Income to Total Assets', 'Bankrupt?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SMData.csv')\n",
    "df = data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c972a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid scoring options: make_scorer(accuracy_score)\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to tune\n",
    "params = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_lambda': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Get a list of valid scoring options\n",
    "valid_scoring = get_scorer('accuracy')\n",
    "print(f\"Valid scoring options: {valid_scoring}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191a99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data['Bankrupt?'])\n",
    "x = df.drop(['Bankrupt?'], axis = 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedf74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 175, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 2971, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: too many positional arguments\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'reg_lambda': 0.01, 'subsample': 0.6}\n",
      "Best evaluation metric:  nan\n"
     ]
    }
   ],
   "source": [
    "XGBModel = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "#Hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=XGBModel, param_grid=params, scoring=accuracy_score)\n",
    "grid_search.fit(x, y)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best evaluation metric: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBModel.fit(x_train, y_train)\n",
    "\n",
    "y_pred = XGBModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Classifier Confusion Matrix\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), \n",
    "           annot=True, fmt='.0f', annot_kws={\"size\":18})\n",
    "\n",
    "print(\"Classification Accuracy: \", XGBModel.score(x_test, y_test))\n",
    "print('TPR: ', get_TPR(y_test, y_pred))\n",
    "print('FPR: ', get_FPR(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGBoost TEST F1 Score: {}'.format(f1_score(y_test,y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
